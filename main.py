"""
===============================================================================
ì‹¤ì‹œê°„ í† ë¡  ë¶„ì„ ì‹œìŠ¤í…œ - Google Cloud API ì§ì ‘ í˜¸ì¶œ ë°ëª¨
===============================================================================

í”„ë¡œì íŠ¸ ëª©ì :
    ì¹œêµ¬ë“¤ë¼ë¦¬ í† ë¡ í•  ë•Œ (ì˜ˆ: "ë°©ë§ì´ë“  ì˜¤íƒ€ë‹ˆ 3ëª… vs ì‚¬ì 1ë§ˆë¦¬")
    ê°ìì˜ ì£¼ì¥ì„ ìŒì„±ìœ¼ë¡œ ë“£ê³ , AIê°€ ë…¼ë¦¬ì™€ ê·¼ê±°ë¥¼ ë¶„ì„í•˜ì—¬ íŒë‹¨

ì‚¬ìš© ê¸°ìˆ :
    1. Google Cloud Speech-to-Text API (ìŒì„±â†’í…ìŠ¤íŠ¸)
    2. Google Vertex AI Gemini API (í…ìŠ¤íŠ¸ ë¶„ì„ ë° íŒë‹¨)

ì½”ë“œ ì¶œì²˜ ë° ì°¸ê³ :
    ì´ ì½”ë“œëŠ” Google Cloud ê³µì‹ ìƒ˜í”Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
===============================================================================
"""

import queue
import sys
import time
from google.cloud import speech_v2 as speech
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
import vertexai
from vertexai.generative_models import GenerativeModel
import pyaudio


# ========== í”„ë¡œì íŠ¸ ì„¤ì • ==========
PROJECT_ID = "knu-sungsu613"  # TODO: Google Cloud í”„ë¡œì íŠ¸ ID ì…ë ¥
LOCATION = "global"
SAMPLE_RATE = 16000
CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms


# ===============================================================================
# 1. MicrophoneStream í´ë˜ìŠ¤
# ===============================================================================
# ì¶œì²˜: GoogleCloudPlatform/python-docs-samples
# íŒŒì¼: speech/microphone/transcribe_streaming_mic.py
# URL: https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/speech/microphone/transcribe_streaming_mic.py
#
# ì„¤ëª…: ë§ˆì´í¬ë¡œë¶€í„° ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ìº¡ì²˜í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì œê³µ
#       pyaudioë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì´í¬ ì…ë ¥ì„ queueì— ì €ì¥í•˜ê³  generatorë¡œ ì œê³µ
# ===============================================================================

class MicrophoneStream:
    """ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ í´ë˜ìŠ¤
    
    Google Cloud ê³µì‹ ìƒ˜í”Œ ì½”ë“œ ê¸°ë°˜
    ì¶œì²˜: python-docs-samples/speech/microphone/transcribe_streaming_mic.py
    """
    
    def __init__(self, rate=SAMPLE_RATE, chunk=CHUNK_SIZE):
        """ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
        
        Args:
            rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ 16000Hz)
            chunk: ì˜¤ë””ì˜¤ ì²­í¬ í¬ê¸° (ê¸°ë³¸ 100ms)
        """
        self._rate = rate
        self._chunk = chunk
        self._buff = queue.Queue()  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•  í
        self.closed = True
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì… - ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì‹œì‘"""
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,      # 16ë¹„íŠ¸ PCM í¬ë§·
            channels=1,                   # ëª¨ë…¸ ì˜¤ë””ì˜¤
            rate=self._rate,
            input=True,                   # ì…ë ¥ ëª¨ë“œ
            frames_per_buffer=self._chunk,
            stream_callback=self._fill_buffer,  # ì½œë°± í•¨ìˆ˜
        )
        self.closed = False
        return self
    
    def __exit__(self, type, value, traceback):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ - ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬"""
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)  # ì¢…ë£Œ ì‹ í˜¸
        self._audio_interface.terminate()
    
    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        """ì˜¤ë””ì˜¤ ì½œë°± í•¨ìˆ˜ - ë§ˆì´í¬ ì…ë ¥ì„ ë²„í¼ì— ì €ì¥
        
        ì„¤ëª…: pyaudioê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œí•˜ëŠ” ì½œë°± í•¨ìˆ˜
              ë§ˆì´í¬ë¡œ ë“¤ì–´ì˜¤ëŠ” ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ queueì— ì €ì¥
        """
        self._buff.put(in_data)
        return None, pyaudio.paContinue
    
    def generator(self):
        """ì˜¤ë””ì˜¤ ì²­í¬ ìƒì„±ê¸°
        
        ì„¤ëª…: queueì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ yield
              Speech-to-Text APIë¡œ ì „ì†¡í•  ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ìƒì„±
        """
        while not self.closed:
            chunk = self._buff.get()
            if chunk is None:
                return
            data = [chunk]
            
            # ë²„í¼ì— ìŒ“ì¸ ì¶”ê°€ ë°ì´í„°ë„ í•¨ê»˜ ê°€ì ¸ì˜¤ê¸°
            while True:
                try:
                    chunk = self._buff.get(block=False)
                    if chunk is None:
                        return
                    data.append(chunk)
                except queue.Empty:
                    break
            
            yield b"".join(data)


# ===============================================================================
# 2. DebateAnalyzer í´ë˜ìŠ¤ (ë©”ì¸ ë¶„ì„ ì‹œìŠ¤í…œ)
# ===============================================================================
# ì½”ë“œ êµ¬ì„±:
#   - Speech-to-Text API ì„¤ì • ë¶€ë¶„: 
#     ì¶œì²˜: GoogleCloudPlatform/generative-ai
#     íŒŒì¼: audio/speech/getting-started/get_started_with_chirp_2_sdk_features.ipynb
#     URL: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/audio/speech/getting-started/get_started_with_chirp_2_sdk_features.ipynb
#
#   - Gemini ë¶„ì„ ë¶€ë¶„:
#     ì¶œì²˜: GoogleCloudPlatform/generative-ai
#     íŒŒì¼: gemini/prompts/examples/text_summarization.ipynb
#     URL: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/examples/text_summarization.ipynb
# ===============================================================================

class DebateAnalyzer:
    """ì‹¤ì‹œê°„ í† ë¡  ë¶„ì„ ì‹œìŠ¤í…œ
    
    ê¸°ëŠ¥:
        1. ë§ˆì´í¬ë¡œ ìŒì„± ì…ë ¥ ë°›ê¸°
        2. Speech-to-Textë¡œ ì‹¤ì‹œê°„ ë³€í™˜
        3. Geminië¡œ ì£¼ì¥ì˜ ë…¼ë¦¬ì™€ ê·¼ê±° ë¶„ì„
    """
    
    def __init__(self, project_id, language_code="ko-KR"):
        """ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            language_code: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: í•œêµ­ì–´ "ko-KR")
        """
        self.project_id = project_id
        self.language_code = language_code
        self.transcript_buffer = []  # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì €ì¥
        
        # Speech-to-Text í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        print("ğŸ”§ Google Cloud Speech-to-Text API ì´ˆê¸°í™” ì¤‘...")
        self.speech_client = SpeechClient()
        
        # Vertex AI Gemini ì´ˆê¸°í™”
        print("ğŸ”§ Google Vertex AI Gemini ì´ˆê¸°í™” ì¤‘...")
        vertexai.init(project=project_id, location="us-central1")
        self.gemini_model = GenerativeModel("gemini-1.5-flash")
        
        print("\nâœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        print(f"   ğŸ“Œ Speech-to-Text: {language_code} ì–¸ì–´ ì¸ì‹")
        print(f"   ğŸ“Œ Gemini Model: gemini-1.5-flash")
        print(f"   ğŸ“Œ Project ID: {project_id}\n")
    
    
    # ===========================================================================
    # Speech-to-Text API ì„¤ì •
    # ===========================================================================
    # ì¶œì²˜: get_started_with_chirp_2_sdk_features.ipynb
    # 
    # ì„¤ëª…: Google Cloud Speech-to-Text V2 API ì„¤ì •
    #       - RecognitionConfig: ìŒì„± ì¸ì‹ ì„¤ì • (ì–¸ì–´, ëª¨ë¸ ë“±)
    #       - StreamingRecognitionConfig: ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • (ì‹¤ì‹œê°„ ì¸ì‹)
    # ===========================================================================
    
    def create_stream_config(self):
        """Speech-to-Text ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ìƒì„±
        
        Google Cloud ê³µì‹ ìƒ˜í”Œ ê¸°ë°˜
        ì¶œì²˜: audio/speech/getting-started/get_started_with_chirp_2_sdk_features.ipynb
        
        Returns:
            StreamingRecognitionConfig: ìŠ¤íŠ¸ë¦¬ë° ì¸ì‹ ì„¤ì •
        """
        
        # 1. Recognition Config ìƒì„±
        recognition_config = cloud_speech.RecognitionConfig(
            # ì˜¤ë””ì˜¤ ì¸ì½”ë”© ìë™ ê°ì§€
            auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),
            
            # ì¸ì‹í•  ì–¸ì–´ ì„¤ì • (í•œêµ­ì–´: ko-KR, ì˜ì–´: en-US)
            language_codes=[self.language_code],
            
            # ëª¨ë¸ ì„ íƒ: "long" = ê¸´ ëŒ€í™”ì— ìµœì í™”ëœ ëª¨ë¸
            # ë‹¤ë¥¸ ì˜µì…˜: "short", "chirp_2", "chirp_3"
            model="long",
            
            # ì¸ì‹ ê¸°ëŠ¥ ì„¤ì •
            features=cloud_speech.RecognitionFeatures(
                enable_automatic_punctuation=True,  # ìë™ ë¬¸ì¥ë¶€í˜¸ ì¶”ê°€
                enable_word_time_offsets=True,      # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
                enable_word_confidence=True,        # ë‹¨ì–´ë³„ ì‹ ë¢°ë„
            )
        )
        
        # 2. Streaming Config ìƒì„±
        streaming_config = cloud_speech.StreamingRecognitionConfig(
            config=recognition_config,
            streaming_features=cloud_speech.StreamingRecognitionFeatures(
                interim_results=True  # ì¤‘ê°„ ê²°ê³¼ë„ ë°˜í™˜ (ì‹¤ì‹œê°„ í‘œì‹œìš©)
            )
        )
        
        return streaming_config
    
    
    # ===========================================================================
    # ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (Speech-to-Text API ì§ì ‘ í˜¸ì¶œ)
    # ===========================================================================
    # ì¶œì²˜: GoogleCloudPlatform/python-docs-samples
    # íŒŒì¼: speech/snippets/transcribe_streaming_v2.py
    # URL: https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/speech/snippets/transcribe_streaming_v2.py
    #
    # ì„¤ëª…: ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ Speech-to-Text APIë¡œ ì „ì†¡í•˜ì—¬ ì‹¤ì‹œê°„ ë³€í™˜
    # ===========================================================================
    
    def transcribe_streaming(self, audio_generator):
        """ì‹¤ì‹œê°„ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜
        
        Google Cloud API ì§ì ‘ í˜¸ì¶œ
        ì¶œì²˜: speech/snippets/transcribe_streaming_v2.py
        
        Args:
            audio_generator: ì˜¤ë””ì˜¤ ë°ì´í„° ìƒì„±ê¸° (MicrophoneStream.generator)
        """
        
        print("\n" + "="*70)
        print("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘")
        print("="*70)
        print("ğŸ’¡ í† ë¡  ë‚´ìš©ì„ ë§ì”€í•´ì£¼ì„¸ìš”. 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print("-"*70 + "\n")
        
        streaming_config = self.create_stream_config()
        
        # ì²« ë²ˆì§¸ ìš”ì²­: ì„¤ì • ì •ë³´
        config_request = cloud_speech.StreamingRecognizeRequest(
            recognizer=f"projects/{self.project_id}/locations/{LOCATION}/recognizers/_",
            streaming_config=streaming_config
        )
        
        def request_generator():
            """API ìš”ì²­ ìƒì„±ê¸°
            
            ì„¤ëª…: ì²« ìš”ì²­ì€ ì„¤ì •, ì´í›„ ìš”ì²­ì€ ì˜¤ë””ì˜¤ ë°ì´í„°
            """
            yield config_request
            for audio_chunk in audio_generator:
                yield cloud_speech.StreamingRecognizeRequest(audio=audio_chunk)
        
        # â˜…â˜…â˜… Google Cloud Speech-to-Text API ì§ì ‘ í˜¸ì¶œ â˜…â˜…â˜…
        responses = self.speech_client.streaming_recognize(
            requests=request_generator()
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        print("ì¸ì‹ ê²°ê³¼:")
        print("-"*70)
        
        for response in responses:
            if not response.results:
                continue
            
            result = response.results[0]
            if not result.alternatives:
                continue
            
            transcript = result.alternatives[0].transcript
            is_final = result.is_final
            confidence = result.alternatives[0].confidence if hasattr(result.alternatives[0], 'confidence') else 0
            
            # ì¤‘ê°„ ê²°ê³¼ í‘œì‹œ (íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ)
            if not is_final:
                print(f"\râ³ [ì¸ì‹ ì¤‘] {transcript}                    ", end="", flush=True)
            else:
                # ìµœì¢… ê²°ê³¼ (í™•ì •ëœ í…ìŠ¤íŠ¸)
                print(f"\râœ… [í™•ì •] {transcript} (ì‹ ë¢°ë„: {confidence:.1%})")
                self.transcript_buffer.append(transcript)
                
                # ì¢…ë£Œ ëª…ë ¹ ì²´í¬
                if "ì¢…ë£Œ" in transcript or "quit" in transcript.lower():
                    print("\n" + "-"*70)
                    print("ğŸ›‘ ìŒì„± ì¸ì‹ ì¢…ë£Œ\n")
                    return
    
    
    # ===========================================================================
    # Geminië¥¼ ì´ìš©í•œ í† ë¡  ë¶„ì„
    # ===========================================================================
    # ì¶œì²˜: GoogleCloudPlatform/generative-ai
    # íŒŒì¼: gemini/prompts/examples/text_summarization.ipynb
    # URL: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/examples/text_summarization.ipynb
    #
    # ì„¤ëª…: Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í† ë¡  ë‚´ìš©ì˜ ë…¼ë¦¬ì™€ ê·¼ê±° ë¶„ì„
    # ===========================================================================
    
    def analyze_debate(self):
        """Geminië¡œ í† ë¡  ë‚´ìš© ë¶„ì„
        
        Google Cloud Gemini API ì§ì ‘ í˜¸ì¶œ
        ì¶œì²˜: gemini/prompts/examples/text_summarization.ipynb
        
        ë¶„ì„ ë‚´ìš©:
            1. ì£¼ìš” ì£¼ì¥ íŒŒì•…
            2. ë…¼ë¦¬ì  ê·¼ê±° í‰ê°€
            3. ê°•ì ê³¼ ì•½ì  ë¶„ì„
            4. ìµœì¢… íŒë‹¨
        """
        
        if not self.transcript_buffer:
            print("âš ï¸  ë¶„ì„í•  í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì „ì²´ ëŒ€í™” ë‚´ìš© ê²°í•©
        full_transcript = "\n".join([
            f"ë°œì–¸ {i+1}: {text}" 
            for i, text in enumerate(self.transcript_buffer)
        ])
        
        print("\n" + "="*70)
        print("ğŸ¤– Gemini AI í† ë¡  ë¶„ì„ ì‹œì‘")
        print("="*70)
        print(f"ğŸ“ ë¶„ì„í•  ë°œì–¸ ìˆ˜: {len(self.transcript_buffer)}ê°œ")
        print("-"*70 + "\n")
        
        # Gemini í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt = f"""
ë‹¹ì‹ ì€ í† ë¡  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í† ë¡  ë‚´ìš©ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ğŸ“‹ í† ë¡  ë‚´ìš©:
{full_transcript}

## ğŸ¯ ë¶„ì„ ìš”ì²­ ì‚¬í•­:

### 1. ì£¼ìš” ì£¼ì¥ ì •ë¦¬
ê° ë°œì–¸ìì˜ í•µì‹¬ ì£¼ì¥ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.

### 2. ë…¼ë¦¬ì  ê·¼ê±° í‰ê°€ (5ì  ë§Œì )
- ê° ì£¼ì¥ì˜ ë…¼ë¦¬ì„±ê³¼ ê·¼ê±°ì˜ íƒ€ë‹¹ì„±ì„ í‰ê°€
- ì ìˆ˜ì™€ í•¨ê»˜ ì´ìœ ë¥¼ ì„¤ëª…

### 3. ê°•ì ê³¼ ì•½ì 
- ê° ì£¼ì¥ì˜ ê°•ì  (ë…¼ë¦¬ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ë¶€ë¶„)
- ê° ì£¼ì¥ì˜ ì•½ì  (ë…¼ë¦¬ì  í—ˆì ì´ë‚˜ ê·¼ê±° ë¶€ì¡±)

### 4. ìµœì¢… íŒë‹¨
- ì–´ëŠ ì£¼ì¥ì´ ë” ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ”ê°€?
- ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?

ë¶„ì„ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
"""
        
        # â˜…â˜…â˜… Google Vertex AI Gemini API ì§ì ‘ í˜¸ì¶œ â˜…â˜…â˜…
        print("â³ Geminiê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n")
        response = self.gemini_model.generate_content(prompt)
        
        print("="*70)
        print("ğŸ“Š AI ë¶„ì„ ê²°ê³¼")
        print("="*70)
        print(response.text)
        print("="*70 + "\n")
        
        return response.text


# ===============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    ì‹¤í–‰ íë¦„:
        1. DebateAnalyzer ì´ˆê¸°í™” (API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •)
        2. ë§ˆì´í¬ë¡œë¶€í„° ì‹¤ì‹œê°„ ìŒì„± ì…ë ¥
        3. Speech-to-Textë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
        4. Geminië¡œ í† ë¡  ë¶„ì„ ë° íŒë‹¨
    """
    
    print("\n" + "="*70)
    print("ğŸ¯ ì‹¤ì‹œê°„ í† ë¡  ë¶„ì„ ì‹œìŠ¤í…œ")
    print("="*70)
    print("ğŸ“Œ ì˜ˆì‹œ ì£¼ì œ: ë°©ë§ì´ë“  ì˜¤íƒ€ë‹ˆ 3ëª… vs ì‚¬ì 1ë§ˆë¦¬, ëˆ„ê°€ ì´ê¸¸ê¹Œ?")
    print("="*70 + "\n")
    
    # 1. ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    analyzer = DebateAnalyzer(
        project_id=PROJECT_ID,
        language_code="ko-KR"  # í•œêµ­ì–´ ì¸ì‹
    )
    
    # 2. ë§ˆì´í¬ë¡œë¶€í„° ì‹¤ì‹œê°„ ìŒì„± ì…ë ¥ ë° ë³€í™˜
    try:
        with MicrophoneStream() as stream:
            audio_generator = stream.generator()
            analyzer.transcribe_streaming(audio_generator)
    except KeyboardInterrupt:
        print("\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    # 3. Geminië¡œ í† ë¡  ë¶„ì„
    analyzer.analyze_debate()
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    """í”„ë¡œê·¸ë¨ ì‹œì‘ì 
    
    ì‹¤í–‰ ì „ í™•ì¸ì‚¬í•­:
        1. Google Cloud í”„ë¡œì íŠ¸ ìƒì„±
        2. Speech-to-Text API í™œì„±í™”
        3. Vertex AI API í™œì„±í™”
        4. ì¸ì¦ ì„¤ì • (gcloud auth application-default login)
        5. PROJECT_ID ë³€ìˆ˜ ìˆ˜ì •
        6. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:
           pip install google-cloud-speech
           pip install google-cloud-aiplatform
           pip install vertexai
           pip install pyaudio
    """
    main()


# ===============================================================================
# ì½”ë“œ ì¶œì²˜ ìš”ì•½
# ===============================================================================
"""
1. MicrophoneStream í´ë˜ìŠ¤:
   - ì¶œì²˜: GoogleCloudPlatform/python-docs-samples
   - íŒŒì¼: speech/microphone/transcribe_streaming_mic.py
   - ê¸°ëŠ¥: ë§ˆì´í¬ ì…ë ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìº¡ì²˜

2. Speech-to-Text ì„¤ì • (create_stream_config):
   - ì¶œì²˜: GoogleCloudPlatform/generative-ai
   - íŒŒì¼: audio/speech/getting-started/get_started_with_chirp_2_sdk_features.ipynb
   - ê¸°ëŠ¥: ìŒì„± ì¸ì‹ API ì„¤ì •

3. ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜ (transcribe_streaming):
   - ì¶œì²˜: GoogleCloudPlatform/python-docs-samples
   - íŒŒì¼: speech/snippets/transcribe_streaming_v2.py
   - ê¸°ëŠ¥: ì‹¤ì‹œê°„ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜

4. Gemini ë¶„ì„ (analyze_debate):
   - ì¶œì²˜: GoogleCloudPlatform/generative-ai
   - íŒŒì¼: gemini/prompts/examples/text_summarization.ipynb
   - ê¸°ëŠ¥: í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½

ëª¨ë“  ì½”ë“œëŠ” Google Cloud ê³µì‹ ìƒ˜í”Œì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°,
í”„ë¡œì íŠ¸ ëª©ì ì— ë§ê²Œ í†µí•© ë° ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
"""
# ===============================================================================